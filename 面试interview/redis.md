## Redis概述

### 1.什么是Redis?

Redis是一个基于内存的高性能的非关系型的键值对数据库，使用C语言编写

### 2.Redis的优缺点？

- 优点：
  - **读写性能好**，读的速度可达11000次/s,写的速度可达81000次/s
  - **支持数据持久化**，有AOF和RDB（默认）两种持久化方式
    - Redis 默认开启RDB持久化方式，在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。
    - AOF ：Redis 默认不开启。它的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个**写操作**，并**追加**到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。
  - 数据结构丰富**，支持string、list、set、hash
  - **支持事务**，redis所有的操作都是原子性的，并且还支持几个操作合并后的原子性执行，原子性值操作要么成功执行，要么失败不执行，不会只执行一部分
  - **支持主从复制**，主机可以自动将数据同步到从机，进行读写分离


- 缺点：
  - 因为Redis是将数据存到内存的，索引会收到内存大小的限制，不能用作海量数据的读写
  - Redis不具备自动容错和恢复功能，主机或从机宕机会导致前端部分读写请求失败，需要重启机器或者手动切换前端的IP才可以

### 3.Redis和Memcached的区别和共同点？

相同点：

- 两者的读写性能都比较高
- 都是基于内存的数据库，通常被当做缓存使用
- 都有过期策略
- 都是基于C语言实现的

不同点：

| 不同点    | Redis                                    | Memcache          |
| ------ | ---------------------------------------- | ----------------- |
| 是否支持复制 | 支持主从复制                                   | 不支持复制             |
| key长度  | 长度最大为2GB                                 | 长度为250个字节         |
| 数据类型   | 不仅支持key-value类型的数据，还支持hash、list、set、zset等数据类型的数据 | 仅支持key-value类型的数据 |
| 数据持久化  | 支持，将数据保存到磁盘                              | 不支持               |
| 网络IO模型 | 单线程的多路IO复用模型                             | 多线程的非常阻塞IO模式      |
| 集群     | 原生支持cluster模式集群                          | 无原生               |

### 4.❤Redis是单线程还是多线程？Redis为什么这么快？

Redis6.0之前是单线程的，为什么Redis6.0之前采用单线程而不是采用多线程

 简单来说，就是Redis官方认为没有必要，**单线程的Redis的瓶颈通常在CPU的IO，而在使用Redis时几乎不存在CPU成为瓶颈的情况**。使用Redis主要的瓶颈在**内存和网络**，并且使用单线程也存在一些优点，比如系统的复杂度较低（实现简单并高效），可为维护性较高，避免了并发读写所带来的的一系列问题。

Redis为什么这么快主要有以下几个原因

- 运行在内存中
- 数据结构简单
- 使用**多路IO复用技术**
- **单线程实现**，单线程避免了线程切换、锁造成的性能开销

### 5.Redis6.0之后为什么引入了多线程？

前面也说了Redis的瓶颈在**内存和网路**，Redis6.0引入多线程主要是为了解决**网络IO**读写这个瓶颈，执行命令还是单线程执行，索引也不存在线程安全问题。

Redis6.0默认是否开启了多线程呢？

默认是没有开启的，如需开启，需要修改配置文件redis.conf:io-threads-do-reads no,no改为yes

### 6.❤Redis的数据类型有哪些？

Redis的常见的数据类型String、Hash、Set、List、ZSet。还有三种不那么常见的数据类型：Bitmap、HyperLogLog、Geospatial

| 数据类型   | 可以存储的只            | 可进行的操作                 | 应用场景         |
| ------ | ----------------- | ---------------------- | ------------ |
| string | 字符串、整数、浮点数        | 对整数或浮点数可以进行自增、自减       | 键值对缓存及常规技术   |
| list   | 列表（内部使用双向列表实现）    | 向列表两端添加元素，或者获的列表的某一个片段 | 存储ID列表       |
| set    | 无序集合（内部使用值为空的散列表） | 增加/删除/获取元素，去交集并集       | 共同好友，共同关注等   |
| zset   | 有序集合（内部使用列表和跳表）   | 添加、获取、删除元素、排名无序        | 去重、后去排名前几的用户 |
| hash   | 包含键值对的散列          | 添加、获取、移除单个键值对          | 常用于存储对象      |

**bitmap**:位图，是一个以位为单位的数组，数组中只能1或0，数组的下标叫偏移量。bitmap实现统计功能，更省空间。面试过程中常问的的布隆过滤器就用到这种数据结构，布隆过滤器可以判断出**哪些数据一定不在数据库中**，所以常用来解决Redis缓存穿透问题

**hyperloglog**: *['haɪpər]*是一种用于**统计基数** 的数据集合类型，

**Geospatial:**ˌ/dʒiːəʊˈspeɪʃəl/ 主要用于存储地理位置信息，常用于定位附近的人，打车距离的计算等。

### 7.❤Redis的数据结构有哪些？

- **简单动态字符串**：Redis的底层是用C语言编写，但Redis并没有直接使用C语言传统的字符串表示，而是构建了一种名为简单动态字符串的抽象类型。

- **链表**：链表提供了高效的节点重排能力，以及顺序性的结点访问方式，并且可以通过增删节点来灵活的调整链表的长度。链表是列表的底层实现之一

- **字典**：又称符号表、关联数组或映射

- **整数集合**：整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。

- **压缩列表（ziplist）**：压缩列表是Redis为了节约内存开发的，是由一系列特殊编码的连续内存组成的顺序型数据结构。

- **对象**：上面的是Redis的底层数据结构，但Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这个系统包含**字符串对象、列表对象、哈希对象、集合对象和有序集合对象**这五种类型的的对象

  为什么不直接使用这些底层数据结构，而是要创建对象系统。对象系统主要有以下优点：

  - 通过五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以给定的命令

  - 我们可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率

  - 实现了基于**引用计数**的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放，

  - 还通过引用计数实现了对象共享机制，这一级至可以再适当的条件下，通过让多个数据库键共享一个对象来节约内存

    ![img](https://image.mianshi.online/img202205212044115.png)


- **跳跃表**（**面试**常问）：跳跃表是一种有序数据结构，它通过在每个节点维持多个指向其他结点的指针，从而达到快速访问节点的目的。平均O(logN)、最坏O(N)复杂度的结点查找，还可以通过顺序性操作来批量处理节点。**跳跃表是有序集合键的底层实现之一** ，跳跃表还在集群节点中用作内部数据结构。跳跃表本质是一种空间换时间的策略，是一种可以进行二分查找的有序链表，跳跃表在原有的有序链表上增加了多级索引，通过索引来实现快速查询。跳表不仅能提高搜索性能，同时可以提高插入和删除操作的性能

  ![img](https://image.mianshi.online/img202205212044631.png)

  建立一级索引：

  ![img](https://image.mianshi.online/img202205212045267.png)

  对于理想的跳跃表，每先上一层索引节点数量都是下一层的1/2,跳跃表为O(logN),空间复杂度为O(N)，虽然是空间换时间的策略，这里距离存储的知识数字，如果是存储比较大的对象，浪费的空间就不值一提了，因为索引节点只需要存储关键值和几个指针，并不需要存储对象

跳跃表相比于红黑树的优点（redis为什么用跳跃表而不是红黑树）：

- **内存**占用更少，自定义参数化决定使用多少内存、查询性能至少不比红黑树差
- 简单更**容易**实现和维护

最后，说下Redis中的跳跃表和普通的跳跃表有什么区别？

- Redis中的跳跃表**分数(score)允许重复**，即跳跃表的key允许重复。如果分数重复，还需要根据数据内容来进行字典排序。普通的跳跃表是不支持的
- 第一层链表不是一个单向链表，而是一个**双向链表**。这是为了方便一倒序方式获取一个范围内的元素。
- 在Redis的跳跃表中可以很方便地计算出每个元素的**排名**

### 8.Redis的应用场景有哪些？

- **缓存**：Redis基于内存，读写速度非常快，并且有键过期功能和键淘汰策略，可以作为缓存使用


- **排行榜**：Redis提供的有序集合可以很方便地实现分布式的锁
- **分布式锁**：Redis的setnx功能来实现分布式的锁
- 社交功能：实现共同好友、共同关注等（sinter命令）
- 计数器(分布式ID生成)：通过对String进行自增自减实现计数功能
- **消息队列**：Redis提供了发布、订阅、阻塞队列等功能，可以实现一个简单的消息队列

### 9.Redis是单线程的，如何提高CPU的利用率？

可以在一个服务器上部署多个Redis实例，把他们当作不同的服务器使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下**分片**（shard）。

## 过期键的删除策略

### 1.键的过期删除策略

常见的过期删除策略时**惰性删除、定期删除、定时删除**

- **惰性删除**：只有访问这个键时才会检查他是否过期，如果过期则删除。优点：最大化地节约CPU资源。缺点：如果大量过期键没有被访问，会一直占用大量内存
- 定时删除：为每一个设置唾弃时间的key都创造一个定时器，到了过期时间就清除。优点：该策略可以立即清除过期的键。缺点：会占用大量CPU资源去处理过期的数据
- **定期删除**：每隔一段时间就对一些键进行检查，删除其中过期的键。该策略时惰性删除和定时删除的一个折中，既避免了占用大量CPU资源又避免了出现大量过期键不被清除占用内存的情况

Redis中同时使用了惰性删除和定期删除两种

### 2.❤Redis的内存淘汰机制是什么样

Redis是基于内存的，所以容量肯定是有限的，有效的内存淘汰机制对Redis非常重要的。

当存入的数据超过Redis最大允许内存后，会触发Redis的内存淘汰策略。在Redis4.0前一共有6种淘汰策略。

- noeviction:不删除策略，达到最大内存限制时，如果需要更多内存，直接返回错误信息。大多数写命令斗都会导致占用更多的内存

- allkeys-lru:所有的key通用，优先删除最近最少使用的key

  **如何用go语言实现LRU（使用双向链表）**

  ```go
  /*
  @Time : 18-11-5 上午10:41 
  @Author : xbx
  @File : lru
  @Software: GoLand
  */
  package main
   
  import "fmt"
   
  type Node struct {
  	Key string
  	Value string
  	pre *Node
  	next *Node
  }
   
  func (n *Node)Init(key string, value string){
  	n.Key = key
  	n.Value = value
  }
   
  var head *Node
  var end *Node
  var limit int

  type LRUCache struct {
  	limit int
  	HashMap map[string]*Node
  }
   
  func GetLRUCache(limit int) *LRUCache{
  	lruCache := LRUCache{limit:limit}
  	lruCache.HashMap = make(map[string]*Node, limit)
  	return &lruCache
  }
   
  func (l *LRUCache)get(key string) string{
  	if v,ok:= l.HashMap[key];ok {
  		l.refreshNode(v)
  		return v.Value
  	}else {
  		return ""
  	}
  }
   
  func (l *LRUCache)put(key , value string) {
  	if v,ok := l.HashMap[key];!ok{
  		if(len(l.HashMap) >= l.limit){
  			oldKey := l.removeNode(head)
  			delete(l.HashMap, oldKey)
  		}
  		node := Node{Key:key, Value:value}
  		l.addNode(&node)
  		l.HashMap[key] = &node
  	}else {
  		v.Value = value
  		l.refreshNode(v)
  	}
  }
   
   
  func (l *LRUCache) refreshNode(node *Node){
  	if (node == end) {
  		return
  	}
  	l.removeNode(node)
  	l.addNode(node)
  }
   
  func (l *LRUCache) removeNode(node *Node) string{
  	if (node == end ) {
  		end = end.pre
  	}else if(node == head){
  		head = head.next
  	}else {
  		node.pre.next = node.next
  		node.next.pre = node.pre
  	}
  	return node.Key
  }
   
   
  func (l *LRUCache) addNode(node *Node){
  	if (end != nil){
  		end.next = node
  		node.pre = end
  		node.next = nil
  	}
  	end = node
  	if (head == nil) {
  		head = node
  	}
  }
   
  func main(){
  	lruCache := GetLRUCache(5)
  	lruCache.put("001", "用户１信息")
  	lruCache.put("002", "用户１信息")
  	lruCache.put("003", "用户１信息")
  	lruCache.put("004", "用户１信息")
  	lruCache.put("005", "用户１信息")
  	lruCache.get("002")
  	lruCache.put("004", "用户２信息更新")
  	lruCache.put("006", "用户6信息更新")
  	fmt.Println(lruCache.get("001"))
   
   
  	fmt.Println(lruCache.get("006"))
  	fmt.Print(lruCache.HashMap)
  }
  ```

  ​

- allkeys-random:所有key通用；随机删除了一部分key

- volatile-lru:[ˈvɒlətaɪl] 只限于设置了expire的部分；优先删除最近最少使用的key

- volatile-random:只限于设置了expire的部分，随机删除最近最少使用的key

- volatile-ttl:只限于设置了expire的部分；优先删除剩余时间短的key

在Redis4.0之后可增加两个

- volatile-lfu:只限于设置了expire的部分；优先删除一些最不经常使用的键（Least Frequenly Used），淘汰最近访问频率最小的元素。
- allkeys-lfu:所有key通用，优先删除最不经常使用的键

## Redis的持久化

### 1.什么是Redis的持久化？

因为Redis是基于内存的，为了防止一些意外导致数据丢失，需要将数据持久化到磁盘上

### 2.Redis常见的持久化机制有哪些？有什么优缺点？

- **RDB** ：Redis默认的持久化方式，按照一定的时间间隔将内存的数据以快照的形式保存到硬盘，恢复时是将快照读取到内存中。RDB持久化实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储

  ![img](https://image.mianshi.online/img202205212222023.png)

  优点：

  - 适合对大规模的数据恢复，比AOF的启动效率高
  - 只有一个文件dump.rdb，方便持久化
  - 性能最大化，在开始持久化时，他唯一需要做的只是-------fork一个子进程，之后再由子进程完成这些持久化的工作，这样就可以极大地避免进程执行IO操作了。

  缺点：

  - 数据安全性低，在一定时间间隔内做一次备份，如果Redis突然宕机，会丢失最后一次快照修改
  - 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒

- **AOF** ：AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到纤细的操作记录。

  ![img](https://image.mianshi.online/img202205212222579.png)

  优点：

  - 具备更高的安全性，Redis提供了3种同步策略，分别是每秒同步、每修改同步和不同步。相比RDB突然宕机丢失的数据会更少，每秒同步只会丢失一秒的数据，每修改同步不会丢失数据。
  - 由于该机制对日志文件的写入操作采用的是append操作，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。
  - AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作，可以通过该文件对完成数据的重建

  缺点：

  - 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB在恢复大数据集时的速度比AOF的恢复速度要快
  - 根据AOF选择同步策略的不同，效率也不同，但AOF在运行效率往往要慢于RDB

## Redis的事务

### 1.什么是Redis的事务

Redis的事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序地执行。事务在执行过程中，不会被其他客户端发送来的命令请求所打断，所以Redis事务是在**一个队列中**，一次性、顺序性、排他性地执行一系列命令

Redis事务的主要作用就是**串联多个命令防止别的命令插队**

### 2.Redis事务的相关命令？

- discard:命令取消事务，放弃执行事务队列内的所有命令，恢复连接为非transaction模式，入股正在使用watch命令监视某个key，那么取消所有监视，等同于执行命令unwatch
- exec:执行事务队列内的所有命令
- multi：['mʌlti] 用于标记一个事务块的开始。
- unwatch，用于取消watch命令对所有key的监视。如果已经执行过了EXEC或DISCARD命令，则无需再执行UNWATCH命令，因为执行EXEC命令时，开始执行事务，WATCH命令也会生效，而 DISCARD命令在取消事务的同时也会取消所有对 key 的监视，所以不需要再执行UNWATCH命令了
- watch:用于标记要监视的key，以便有条件地执行事务，watch命令可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行

### 3.Redis事务执行的三个阶段

1.开始事务（multi *['mʌltɪ]*）

2.命令入列

3.执行事务（exec)

### 4.Redis事务的特性

- Redis事务**不保证原子性**，单条的Redis命令是原子性的，但事务不能保证原子性
- Redis事务是有**隔离性**的，但是没有隔离级别，事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送过来的命令请求所打断（**顺序性、排他性**）
- Redis事务**不支持回滚** ，Redis执行过程中的命令执行失败，其他命令仍然可以执行

### 5.Redis事务为什么不支持回滚？

在Redis的事务中，命令允许失败，但是Redis会继续执行其他的命令而不是回滚所有命令，是不支持回滚的

主要原因有以下两点：

- Redis命令简单，只在两种情况失败
  - 语法错误的时候才失败（在命令输入的时候不检查语法）
  - 要执行的key数据类型不匹配：这种错误实际上是编程错误，这应该在开发阶段被测试出来，而不是在生产上
- 因为不需要回滚，所以Redis**内部实现简单并高效**。（Redis为什么是单线程而不是多线程也用了这个思想，实现简单并且高效）

## Redis的集群、主从、哨兵

### 1.❤Redis集群的实现方案有哪些？

在说Redis集群前，先说为什么要使用Redis集群，Redis单机版主要有以下几个缺点：

- 不能保证数据的**可靠性**，服务部署在一台服务器上，一旦服务器宕机就不可用，
- **性能瓶颈**，内存容量有限，处理能力有限

Redis集群就是为了解决Redis单机版的一些问题，Redis集群主要是有以下几种方案**Redis主从模式** ，**Redis哨兵模式** ，**Redis自研** ，**Redis Cluster**

#### **Redis主从模式** 

Redis单机版通过RDB或AOF持久化机制到硬盘上，但数据都存储在一台服务器上，并且读写都在同一服务器上（读写不分离），如果硬盘出现问题，则会导致数据不可用，为了避免这种问题，

Redis提供了复制功能，在master数据库中的数据更新后，自

动将更新的数据同步到slave数据库中，这就是主从模式的Redis集群，如下图：

![img](https://image.mianshi.online/img202205212227127.png)

主从模式解决了Redis单机版存在的问题，但其本身也不是完美的，主要优缺点如下：

- **优点：**
  - **高可靠性** ，在master数据库出现故障后，可以切换到salve数据库
  - **读写分离**，slave库可以扩展master库节点的读能力，有效应对大并发量的读写操作


- **缺点：**
  - 不具备自动容错和恢复能力，主节点故障，从节点需要手动升为主节点，可用性较低

#### **Redis哨兵模式**

为了解决主从模式的Redis集群不具备自动容错和恢复能力的问题，Redis从2.6开始提供哨兵模式

哨兵模式的核心还是主从复制，不过相比于主从模式，多了一个竞选机制（多了一个哨兵集群），从所有从节点中选出主节点，如下图：

![img](https://image.mianshi.online/img202205212227599.png)

哨兵模式相比于主从模式，主要多了一个哨兵集群，哨兵集群的主要作用如下：

- 监控所有服务器是否正常运行：通过发送命令返回监控服务器的运行状态（心跳），处理监控主服务器、从服务器外，哨兵之间也相互监控
- 故障切换：当哨兵监测到master宕机，会自动将某个slave切换到master，然后通过**发布订阅模式** 通知其他的从服务器，修改配置文件，让他们切换master。同时那台有问题的旧主也会变成新主的从节点，也就是说当就的主节点即使恢复时，并不会恢复原来的主节点身份，而是作为新主节点的一个从节点


- **优点：**
  - 哨兵模式是基于主从模式的，解决主从模式中master故障不可以自动切换master的问题


- **缺点：**
  - 浪费资源，集群里所有节点保存的都是全量数据，数据量	过大时，主从同步会严重影响性能
  - Redis主机宕机后，投片选举结束之前，谁也不知道主机和从机是谁，此时Redis也会开启保护机制，禁止写操作，直到选举出了新的Redis主机
  - 只有一个master库执行写请求，写操作会单机性能瓶颈影响

#### **Redis自研**

哨兵模式虽然解决了主从模式存在的一些问题，但其本身也存在一些弊端，比如数据在每个Redis实例中都试试全量存储，极大地浪费了资源，为了解决这个问题，Redis提供了Redis Cluster,实现了数据分片存储，但Redis提供Redis Cluster之前，很多公司为了解决哨兵模式存在的问题，分别自行研发Redis集群方案：

- **客户端分片**

客户端分片是把分片的逻辑放在Redis客户端实现，通过Redis预先定义好的路由规则（使用哈希算法），把对Key的访问转发到不同的Redis实例中，查询数据时把返回结果回汇集。如下图：

![img](https://image.mianshi.online/img202205212228595.png)

**优点** ：Redis实例彼此独立，相互无关联，每个Redis实例想单个服务器一样运行，非常容易线性扩展，系统的灵活性很强

**缺点：**

- Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行
- 运维成本比较高，集群的数据出了任何问题都需要运维人员和开发人员一起合作，减缓了解决问题的速度，增加了跨部门沟通的成本
- 在不同的客户端程序中，维护相同的路由分片逻辑成本巨大。比如java项目，go项目里共用一套Redis集群，路由分片逻辑分别需要写两套一样的逻辑，以后维护也是两套


- **代理分片** ：

  客户端分片的最大问题就是服务端Redis实例群拓扑结构有变化时，每个科幻都需要更新调整

  为了解决这个问题，代理分片出现了，代理分片将客户端分片模块单独分了出来，作为Redis客户端和服务端的桥梁，如下图：

  ![代理分片](https://image.mianshi.online/img202205212228361.png)

  **优点**：解决了服务端Redis实例拓扑结构有变化时，每个客户端都需要更新调整的问题。

  **缺点** ：由于Redis客户端的每个请求都经过代理才能达到Redis服务器，这个过程中会产生**性能损失**

  （常见的代理分片有Twitter开源的Redis代理Twemproxy和豌豆荚自主研发的Codis）

#### Redis Cluster

在Redis3.0中，Redis也提供了响应的解决方案，就是Redis Cluster

Redis Cluster是一种服务端Sharding技术，并没有采用一致性哈希，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的结点会将查询请求发送到正确的结点上执行。

**一致性哈希**

首先对key计算出一个hash值，然后对2^32取模，将其范围抽象成一个**圆环**，使用CRC16算法计算出来的哈希值回落到圆环的某个地方

![img](https://image.mianshi.online/img202205212229359.jpg)

假设A、B、C三个Redis实例按照如图所示的位置分布在圆环上，通过上述介绍的方法计算出key的hash值，发现其落在了位置E，按照顺时针，这个key值应该分配到Redis实例A上。 如果此时Redis实例A挂了，会继续按照顺时针的方向，之前计算出在E位置的key会被分配到RedisB，而其他Redis实例则不受影响。

但一致性哈希也不是完美的，主要存在以下问题：**当Redis实例节点较少时，节点变化对整个哈希环中的数据影响较大，容易出现部分节点数据过多，部分节点数据过少的问题，出现数据倾斜的情况**，如下图（图片来源于网络），数据落在A节点和B节点的概率远大于B节点

![img](https://image.mianshi.online/img202205212229481.jpg)

为了解决这种问题，可以对一致性哈希算法引入**虚拟节点**（A#1，B#1，C#1），如下图（图片来源于网络）

![img](https://image.mianshi.online/img202205212229604.jpg)

那这些虚拟节点有什么用呢？每个虚拟节点都会映射到真实节点，例如，计算出key的hash值后落入到了位置D，按照顺时针顺序，应该落到节点C#1这个虚拟节点上，因为虚拟节点会映射到真实节点，所以数据最终存储到节点C。

**Redis虚拟槽**

在Redis Cluster中并没有使用一致性哈希，而引进了虚拟槽。虚拟槽的原理和一致性哈希好像，Redis Cluster一共有2^14(16384)个槽，所有的master节点都会有一个范围比如0~1000，槽数是可以迁移的。master节点的slave节点不分配槽，只拥有读权限，其实虚拟槽也可以看成一致性哈希中的虚拟节点。

虚拟槽和一致性哈希算法的实现也很像，先通过CRC16算法计算出key的hash值，然后对16384取模，得到对应的槽位，根据槽找到对应的节点，如下图：

![img](https://image.mianshi.online/img202205212229247.jpg)

**优点：** **更加方便地添加和移除节点**，增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了，当移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了，不需要停掉Redis任何一个节点的服务，采用一致性哈希算法时增加和移除节点需要rehash

Redis Cluster是一个去中心化的架构，不存在统一的配置，Redis Cluster的每个节点都保存了集群的配置信息，在Redis Cluster中，这个配置信息通过Redis Cluster Bus进行交互，并最后达成一致性。

配置信息的一致性主要是PING/PONG,每个节点向其他节点周期性的发送Ping/Pong消息。对于大规模的集群，如果每次Ping/Pong都携带者所有节点的信息，则网络开销会很大。此时Redis Cluster在每次Ping/Pong，只包含了随机一部分节点信息。由于交互比较频繁，集群的状态也会达到一致

在Cluster结构不发生变化时，各个节点通过gossip协议（Redis Cluster各个节点之间交换数据、通信采用的一种协议）在几轮交互后，便可以得知Cluster的结构信息，达到一致性的状态。但是当集群结构发生变化时（故障转移、分片迁移）时，有幸得知变更的节点会将自己的最新信息扩散到Cluster，并达到最终一致

Redis Bus是用于节点之间的信息交路，交互的信息有以下几个：

- 数据分片（slot）和节点的**对应关系**
- 集群中每个节点**可用状态**
- 集群结构发生变更时，通过一定的协议对**配置信息达成一致**。数据分片的迁移，主备切换、单点master的发现和其发生主备关系变更等，都会导致集群结构的变化

### 2.Redis主从架构中数据丢失吗？

Redis主从架构丢失数据主要有两种情况

- **异步复制同步丢失**

  Redis主节点和从节点的复制是异步的，当主节点的数据未完全复制到从节点时就会发生宕机了，master内存中的数据会丢失

  如果主节点开启持久化是否可以解决这个问题？

  答案是**否定的**，在master发生宕机后，集群检测到主节点发生故障，重新选举新的主节点，如果就的主节点在故障恢复后重启，那么此时他需要同步新节点的数据，此时新的主节点的数据是空的（假设这段时间中没有数据写入）。那么旧主机点中的数据就会被刷新掉，此时数据还是会丢失

- **集群产生脑裂**

  集群脑裂是指一个集群中有多个主节点，像一个人有两个大脑，到底听谁的

  例如，由于网络原因，集群出现了分区，master和slave节点断开了联系，哨兵监测后认为主节点故障，重新选举从节点为主节点，但主节点可能并没有发生故障。此时客户端依然在旧的主节点上写数据，而新的主节点中没有数据，在发现这个问题之后，旧的主节点会被降为slave，并且开始同步新的master数据，那么之前的写入旧的主节点的数据被刷新掉，大量数据丢失。

### 3.如何解决Redis主从架构数据丢失的问题？

在Redis的配置文件中，有两个参数如下： 

```yaml 
min-slaves-to-write 1 

min-slaves-max-lag 10 
```

其中，min-slaves-to-write默认情况下是0，min-slaves-max-lag默认情况下是10。 

上述参数表示至少有1个salve的与master的同步复制延迟不能超过10s，一旦所有的slave复制和同步的延迟达到了10s，那么此时master就不会接受任何请求。 

通过降低min-slaves-max-lag参数的值，可以避免在发生故障时大量的数据丢失，一旦发现延迟超过了该值就不会往master中写入数据。

这种解决数据丢失的方法是降低系统的可用性来实现的。

### 4.Redis集群的主从复制过程是什么样的？

1.设置服务器的地址和端口号

2.建立套接字（建立主从服务器之间的连接）

3.发送Ping命令（检验套接字是否可用）

4.身份验证

5.命令传播（经过上面同步操作，此时主从的数据库状态其实已经一致了，许主服务器马上就接受到了新的写命令，执行完该命令后，主从的数据库状态又不一致。数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性）

### 5.简单解释下全量复制和部分复制？

在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。 

- 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 
- 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。

### 6.Redis是如何保证主从服务器一直处于连接状态以及命令是否丢失

命令传播阶段，从服务器会利用**心跳检测机制**定时的向主服务发送消息。

### 7.因为网络原因在主从复制过程中停止复制会怎么样？

如果出现网络问题断开，**会自动重连，并且支持断点续传，接着上次复制的地方继续复制**，而不是重新复制一份。

### 8.Redis集群最大的节点个数是多少？为什么？

16384个，因为Redis集群采用哈希槽分片，而哈希槽总共有16384个。

由于其他设计折衷，一般情况下一个redis集群不会有超过**1000**个master节点

### 9.Redis集群是如何选择数据库的？

Redis集群目前无法做到护具库选择，默认在0数据库

### 10.Redis高可用方案如何实现？

- 数据持久化
- 主从模式
- 哨兵模式
- Redis集群（自研及Redis Cluster）

## Redis的分区

### 1.Redis分区的作用是什么？

- **扩展数据库容量**，可以利用多台机器的内存构建更大的数据库 
- **扩展计算能力**，分区可以在多核和多计算机之间弹性扩展计算能力，在多计算机和网络适配器之间弹性扩展网络带宽

### 2.❤Redis分区有哪些实现方案？

在介绍Redis集群的实现方案时已经介绍过了客户端分区和代理分区，常见的Redis分区方案主要有以下三种：

-  **客户端分区**：客户端决定数据被存到哪个Redis节点或者从哪个节点读取 
-  **代理分区**：客户端将请求发送到代理，而不是直接发送到Redis节点，代理根据分区策略将请求发送到Redis节点上
-  **查询路由**：客户端随机请求任意一个Redis节点，这个Redis节点将请求转发到正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，并不是直接将请求从一个Redis节点转发到另一个Redis节点，而是在客户端的帮助下直接重定向到正确的redis节点

### **3.Redis分区的缺点？**

- **不支持多个键的操作**，例如不能操作映射在两个Redis实例上的两个集合的交叉集。（其实可以做到这一点，但是需要间接的解决）
- **不支持多个键的事务**
- Redis是以键来分区，因此不能使用单个大键对数据集进行分片，例如一个非常大的有序集
- **数据的处理会变得复杂**，比如你必须处理多个RDB和AOF文件，在多个实例和主机之间持久化你的数据
- 添加和删除节点也会变得复杂，例如通过在运行时添加和删除节点，Redis集群通常支持透明地再均衡数据，但是其他系统像客户端分区或者代理分区的特性就不支持该特性。不过Pre-sharding(预分片)可以在这方面提供帮助。

## Redis的分布式问题

### 1.什么是分布式锁？

锁在程序中的作用主要是同步，就是保证共享资源在同一时刻只能被同一个线程访问。 分布式锁则是为了保证在分布式场景下，共享资源在同一时刻只能被同一个线程访问，或者说是用来控制分布式系统之间同步访问共享资源。

### 2.分布式锁具有哪些特性？

- 互斥性：在任意时刻，同一条数据只能被一台机器上的一个线程执行 
- 高可用性：当部分节点宕机后，客户端仍可以正常地获取锁和释放锁 
- 独占性：加锁和解锁必须同一台服务器执行，不能在一个服务器上加锁，在另一个服务器上释放锁 
- 防锁超时：如果客户端没有主动释放锁，服务器会在一定时间后自动释放锁， 防止客户端宕机或者网络异常导致宕机

### 3.❤分布式锁的实现方法？

基本思路就是要在整个系统中提供一个全局、唯一的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。 常见的分布式锁实现方案有三种：

###### **基于关系型数据库**：

> 它的基本原理和 Redis 的 SETNX 类似，其实就是创建一个分布式锁表，加锁后，我们就在表增加一条记录，释放锁即把该数据删掉
>
> 乐观锁和悲观锁
>
> 它同样存在一些问题：
>
> 1. 没有失效时间，容易导致死锁；
> 2. 依赖数据库的可用性，一旦数据库挂掉，锁就马上不可用；
> 3. 这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作；
> 4. 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据库中数据已经存在了。

 **优点**：直接借助数据库容易理解

 **缺点**： 在使用关系型数据库实现分布式锁的过程中会出现各种问题，例如数据库单点问题和可重入问题，并且在解决过程中会使得整个方案越来越复杂

###### **基于Redis**： 

基本命令主要有：

- SETNX(SET If Not Exists)：当且仅当 Key 不存在时，则可以设置，否则不做任何动作。
- SETEX：可以设置超时时间

其原理为：通过 SETNX 设置 Key-Value 来获得锁，随即进入死循环，每次循环判断，如果存在 Key 则继续循环，如果不存在 Key，则跳出循环，当前任务执行完成后，删除 Key 以释放锁。

这种方式可能会导致死锁，为了避免这种情况，需要设置**超时时间**。

**优点**：性能好，实现起来较为方便

**缺点**： key的过期时间设置难以确定，如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。 Redis的集群部署虽然能解决单点问题，但是并不是强一致性的，锁的不够健壮;高并发的情况下，如果两个线程同时进入循环，可能导致加锁失败。

**利用Redlock**

获取锁的步骤：

假设有N个redis节点，这些节点之间既没有主从，也没有集群关系。

- 客户端用相同的key和随机值在N 个节点上请求锁，请求锁的超时时间应小于锁自动释放时间。
- 当在（N/2+1）个（超过半数）redis上请求到锁的时候，才算是真正获取到了锁。
- 如果没有获取到锁，则把部分已锁的redis释放掉。

通过 Redlock 实现分布式锁比其他算法更加可靠

###### **基于zookeeper**： 

> 实现是基于临时序号节点，每个客户端对某个方法加锁时，在 Zookeeper 上与该方法对应的指定节点的目录下，生成一个唯一的临时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个临时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

锁分为两种：共享锁（读锁）和排他锁（写锁）

- 读锁：当有一个线程获取读锁后，其他线程也可以获取读锁，但是在读锁没有完全被释放之前，其他线程不能获取写锁。
- 写锁：当有一个线程获取写锁后，其他线程就无法获取读锁和写锁了。

zookeeper有一种节点类型叫做临时序号节点，它会按序号自增地创建临时节点，这正好可以作为分布式锁的实现工具。

读锁获取原理：
1、根据资源的id创建临时序号节点：/lock/mylockR0000000005 Read
2、获取/lock下的所有子节点，**判断比他小的节点是否全是读锁**，如果是读锁则获取锁成功
3、如果不是，则阻塞等待，**监听**自己的前一个节点。
4、当前面一个节点发生变更时，重新执行第二步操作。

写锁获取原理：
1、根据资源的id创建临时序号节点：/lock/mylockW0000000006 Write
2、获取 /lock 下所有子节点，**判断最小的节点是否为自己**，如果是则获锁成功
3、如果不是，则阻塞等待，**监听**自己的前一个节点
4、当前面一个节点发生变更时，重新执行第二步。




![排它锁](https://img2018.cnblogs.com/blog/1010726/201909/1010726-20190929122006568-809468321.png)



**优点**：有效地解决单点问题，**不可重入问**题，非阻塞问题以及锁无法释放的问题，实现起来较为简单。

 **缺点**：性能上不如使用Redis实现分布式锁

### 4.❤Redis如何实现分布式锁？

Redis实现分布式锁的主要命令：SETNX，该命令的作用是当key不存在时设置key的值，当Key存在时，什么都不做。 但是这个简陋的分布式锁存在很多问题，并不能满足上述介绍的分布式锁的特性， 比如，当线程1执行到上图中执行业务这步时，业务代码突然出现异常了，无法进行删除锁这一步，那就完犊子了，死锁了，其他线程也无法获取到锁了（因为SETNX的特性）。 

**改进方案1：设置超时时间** 

其实这个问题很好解决，只需给锁设置一个**过期时间**就可以了，对key设置过期时间在Redis中是常规操作了。就是这个命令SET key value [EX seconds][PX milliseconds] [NX|XX] EX second: 设置键的过期时间为second秒； PX millisecond：设置键的过期时间为millisecond毫秒； NX：只在键不存在时，才对键进行设置操作； XX：只在键已经存在时，才对键进行设置操作； SET操作完成时，返回OK，否则返回nil。 

那先现在这个方案就完美了吗？显然没有 例如，线程1获取到了锁，并设置了有效时间10秒，但线程1在执行业务时超过了10秒，锁到期自动释放了，在锁释放后，线程2又获取了锁，在线程2执行业务时，线程1执行完了，随后执行了删除锁这一步，但是线程1的锁早就到期自动释放了，他删除的是线程2的锁！！！ 

**改进方案2：超时时间+标识+守护线程** 

其实看起来方案1的问题很容易解决，只需要把锁的过期时间设置的非常长，就可以避免这两个问题，但是这样并不可行，因为这样相当于回到最简陋的方案（会导致李四一直上不到厕所）。 那如何能让李四上到厕所，还不会让自己锁的门被张三打开门呢？ 

很简单，为锁加一个**标识**，例如生成一个UUID，作为锁的标识，每个线程获取锁时都会生成一个不同的UUID作为锁的标识，在进行删除锁时会进行判断，锁的标识和自己生成UUID相等时才进行删除操作，这样就避免线程1释放了线程2的锁。（相当于自己上自己的锁，不要计较为什么张三在李四上厕所时不需要李四的钥匙就能离开厕所这种事，上厕所和分布式锁逻辑并不完全相同，只是简单类比） 那怎么解决李四未等张三上完厕所就进厕所呢？（如何确定锁的过期时间） 

可以在加锁时，先设置一个预估的过期时间，然后开启一个**守护线程**，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行续期，重新设置过期时间。 好了，张三和李四上厕所的解决了。 那此方案就没有其他问题了吗？其实还是有的，比如目前的分布式锁还不具备可重入性（同一线程可以重复获取锁，解决线程需要多次进入锁内执行任务的问题） 

**改进方案3：计数** 

参考其他重入锁的实现，可以通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时才能释放锁。 那现在方案就没有问题了吗，其实还有 比如，线程1获取了锁，线程2没有获取到锁，那么线程2怎么知道线程1啥时候释放了锁，进而再去获取锁呢？

 **改进方案4：客户端轮询** 

方案3中问题的解决方案，一般以下两种解决方案： 

可以通过客户端轮询的方式，就是线程2过一会就来看看是不是能获取锁了。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。 

通过Redis的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。 那现在这个方案完美了吗？也还没有 目前讨论的都是redis是单节点的情况，如果这个节点挂了，那么所有的客户端都获取不到锁了

 **改进方案5：红锁** 

> 为了实现多节点Redis的分布式锁，Redis的作者提出了RedLock算法。 这是RedLock算法官网的地址，https://redis.io/topics/distlock，英文好的建议直接看官方文档，
>
>  **为什么基于故障转移实现的Redis分布式锁还不够用？** 
>
> 官网中举了一个例子： 
>
> 客户端A获得主服务器上的锁，然后主服务器向从服务器复制数据的过程中崩了，导致数据没有复制到从数据库中，这时会在从服务器中选出来一个升级为主服务器，但新的主服务器中并没有客户端A设置的锁。所以客户端B也可以获取到锁，违背了上面说的互斥性 
>
> 这就解释为什么需要RedLock算法

Redlock获取锁的步骤：

假设有N个redis节点，这些节点之间既没有主从，也没有集群关系。

- 客户端用相同的key和随机值在N 个节点上请求锁，请求锁的超时时间应小于锁自动释放时间。
- 当在（N/2+1）个（超过半数）redis上请求到锁的时候，才算是真正获取到了锁。
- 如果没有获取到锁，则把部分已锁的redis释放掉。

**RedLock算法是异步的吗？** 

可以看成**同步**算法，虽然没有跨进程的同步时钟，但每个进程（多个电脑）的本地时间仍然大致以相同的速度流动，与锁的自动释放时间相比，误差较小，将其忽略的话，则可以看成同步算法。 

**RedLock失败重试**

 当客户端无法获取到锁时，应该在随机时间后重试，并且理想的客户端应该并发地将所有命令用时发给所有Redis实例。对于已经获取锁的客户端要在完成任务后及时释放锁，这样其他客户端就不需要等锁自动过期后在获取。如果在获取锁后，在主动释放锁前无法连接到Redis实例，就只能等锁自动失效了。 

**释放锁** 

释放锁很简单，只要释放所有实例中的锁，不需要考虑是否释放成功（释放时会判断这个锁的value值是不是自己设置的，避免释放其他客户端设置的锁） 

**RedLock的 Safety arguments** 

- 假设客户端可以获取到大多数Redis实例，并且所有Redis实例具有相同的key和过期时间，但不同的Redis实例的key是不同的时间设置的（获取锁的时间不可能完全一致），所以过期时间也不同，假设获取第一个Redis实例的锁的时间为T1,最后一个为T2，则客户端获得锁的最小有效时间为key的有效时间-（T2-T1）-时钟漂移。 
- 为什么需要获取一半以上的Redis实例的锁才算获取到锁成功呢？因为如果获取不到一半也算成功的话会导致多个客户端同时获取到锁，违背了互斥性 
- 一个客户端锁定大多数Redis实例所需的时间大于或者接近锁的过期时间时，会认为锁无效，并解锁所有Redis实例 

**RedLock崩溃的相关解决方法** 

场景：客户端A在成功获取锁后，如果所有Redis重启，这时客户端B就可以再次获取到锁，违背了互斥性 

解决方法：**开启AOF持久化**，可以解决这个问题，但是AOF同步到磁盘上的方式默认是每秒一次，如果1秒内断电，会导致1秒内的数据丢失，如果客户端是在这1秒内获得的锁，立即重启可能会导致锁的互斥性失效，解决方法是每次Redis无论因为什么原因停掉都要等key的过期时间到了在重启（**延迟重启**），这么做的缺点就是在等待重启这段时间内Redis处于关闭的状态。 

### 5.Redis并发竞争key问题应该如何解决？

Redis并发竞争key就是多个客户端操作一个key，可能会导致数据出现问题，主要有以下几种解决办法：

- **乐观锁**，watch 命令可以方便的实现乐观锁。watch 命令会监视给定的每一个key，当 exec 时如果监视的任何一个key自从调用watch后发生过变化，则整个事务会回滚，不执行任何动作。不能在分片集群中使用 
- **分布式锁**，适合分布式场景 
- **时间戳**，适合有序场景，比如A想把key设置为1，B想把key设置为2，C想把key设置为3，对每个操作加上时间戳，写入前先比较自己的时间戳是不是早于现有记录的时间戳，如果早于，就不写入了
- **消息队列**，串行化处理

## Redis的缓存问题

### 1.❤说下什么是缓存雪崩、缓存穿透、缓存击穿，及它们的解决方案

> 这是一个非常高频的面试题，也非常容易掌握，比较麻烦的是总是分不清这三个哪个是哪个

**缓存雪崩**

缓存雪崩是指在某一个时刻出现大规模的缓存失效的情况，大量的请求直接打在数据库上面，可能会导致数据库宕机，如果这时重启数据库并不能解决根本问题，会再次造成缓存雪崩。 

为什么会造成缓存雪崩？

 一般来说，造成缓存雪崩主要有两种可能 

- Redis宕机了


-  很多key采取了相同的过期时间 

如何解决缓存雪崩？

-  为避免Redis宕机造成缓存雪崩，可以搭建Redis集群 
-  尽量不要设置相同的过期时间，例如可以在原有的过期时间加上随机数
-  服务降级，当流量到达一定的阈值时，就直接返回“系统繁忙”之类的提示，防止过多的请求打在数据库上，这样虽然难用，但至少可以使用，避免直接把数据库搞挂

**缓存击穿**

缓存雪崩是大规模的key失效，而缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增，这种现象就叫做缓存击穿。 比较经典的例子是商品秒杀时，大量的用户在抢某个商品时，商品的key突然过期失效了，所有请求都到数据库上了。

 如何解决缓存击穿 

- 热点key不设置过期时间，避免key过期失效 
- 加锁，如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库宕机，不过这样会导致系统的性能变差。

**缓存穿透**

缓存穿透是指用户的请求没有经过缓存而直接请求到数据库上了，比如用户请求的key在Redis中不存在，或者用户恶意伪造大量不存在的key进行请求，都可以绕过缓存，导致数据库压力太大挂掉。 

如何解决缓存穿透

- **参数校验**，例如可以对用户id进行校验，直接拦截不合法的用户的请求 
- **布隆过滤器**，布隆过滤器可以判断这个key在不在数据库中，特点是如果判断这个key不在数据库中，那么这个key一定不在数据库中，如果判断这个key在数据库中，也不能保证这个key一定在数据库中。就是会有少数的漏网之鱼，造成这种现象的原因是因为布隆过滤器中使用了hash算法，对key进行hash时，不同的key的hash值一定不同，但相同的hash的值不能说明这两个key相同。下面简单介绍下布隆过滤器，这个面试也常问。

布隆过滤器底层使用bit数组存储数据，该数组中的元素默认值是0。 

布隆过滤器第一次初始化的时候，会把数据库中所有已存在的key，经过一系列的hash算法计算，算出每个key的位置，并将该位置的值置为1，为了减少哈希冲突的影响，可以对每个key进行多次hash计算，如下图

- 通过k个无偏hash函数计算得到k个hash值
- 依次取模数组长度，得到数组索引
- 判断索引处的值是否全部为1，如果全部为1则存在（这种存在可能是误判），如果存在一个0则必定不存在

![img](https://image.mianshi.online/img202205252130147.jpg)

那使用布隆过滤器就可以完美解决问题了吗？当然没有，使用布隆过滤器解决缓存穿透问题的同时也带来了一些其他问题： 

- 布隆过滤器存在误判的情况 
- 布隆过滤器不支持删除，因为布隆过滤器中存的1可能涉及多个key，直接删除可能会影响到其他key，比如上图第四个位置的1就涉及两个key 
- 如果数据库中数据更新同步到布隆过滤器时失败，布隆过滤器则会将本来正常的请求拦截住，这是非常致命的 

先来看第一个问题，前面已经解释过了布隆过滤器存在误判的原因，就是不同的key的hash值可能相同。因为每个key要经过多次hash计算，恰好每次hash计算都和其他key的hash值相同的概率是很低的，有少数的漏网之鱼通过了布隆过滤器也不要紧，所以第一个问题不必担心。如果想要减少hash冲突导致的误判，可以适当**增加key的hash次数**。

第二个问题可以在布隆过滤器中以**计数**的方式存储，如下图

![img](https://image.mianshi.online/img202205252130926.jpg)

第三个问题出现概率不大，如果这种问题对业务影响很大，可以考虑其他解决缓存穿透的方法。

### 2.❤如何保证缓存与数据库双写时的数据一致性？

> 这是面试的高频题，需要好好掌握，这个问题是没有最优解的，只能数据一致性和性能之间找到一个最适合业务的平衡点

首先先来了解下一致性，在分布式系统中，一致性是指多副本问题中的数据一致性。一致性可以分为强一致性、弱一致性和最终一致性 

强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。强一致性对用户比较友好，但对系统性能影响比较大。

 弱一致性：系统并不保证后续进程或者线程的访问都会返回最新的更新过的值。

最终一致性：也是弱一致性的一种特殊形式，系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。

**先更新数据库，后删除缓存**

这种方案也存在一个问题，如果更新数据库成功了，删除缓存时没有成功，那么后面每次读取缓存时都是错误的数据。

解决这个问题的办法是**删除重试机制**，常见的方案有利用消息队列和数据库的日志 

利用**消息队列**实现删除重试机制，如下图

![img](https://image.mianshi.online/img202205252121998.jpg)

步骤在图中写的已经比较清除了，这里简单说下为什么使用消息队列，消息队列可以保证写到队列中的消息在成功消费之前不会消失，并且在第4步中获取消息时只有消费成功才会删除消息，否则会继续投递消息给应用程序，符合消息重试的要求。

但这个方案也有一些缺点，比如系统复杂度高，对业务代码入侵严重，这时可以采用订阅数据库日志的方法删除缓存。如下图

![img](https://image.mianshi.online/img202205252121831.jpg)

**先删除缓存，后更新数据库**

这种方案也存在一些问题，比如在并发环境下，有两个请求A和B，A是更新操作，B是查询操作 

1.假设A请求先执行，会先删除缓存中的数据，然后去更新数据库 

2.B请求查询缓存发现为空，会去查询数据库，并把这个值放到缓存中 

3.在B查询数据库时A还没有完全更新成功，所以B查询并放到缓存中的是旧的值，并且以后每次查询缓存中的值都是错误的旧值

这种情况的解决方法通常是采用**延迟双删**，就是为保证A操作已经完成，最后再删除一次缓存

![img](https://image.mianshi.online/img202205252122765.jpg)

逻辑很简单，删除缓存后，休眠一会儿再删除一次缓存，虽然逻辑看起来简单，但实现起来并不容易，问题就出在延迟时间设置多少合适，延迟时间一般大于B操作读取数据库+写入缓存的时间，这个只能是估算，一般可以考虑读业务逻辑数据的耗时 + 几百毫秒。

在实际应用中，还是**先更新数据库后删除缓存**这种方案用的多些。

 需要注意的是，无论哪种方案，如果数据库采取读写分离+主从复制延迟的话，即使采用先更新数据库后删除缓存也会出现类似先删除缓存后更新数据库中出现的问题，举个例子 

1.A操作更新主库后，删除了缓存 

2.B操作查询缓存没有查到数据，查询从库拿到旧值 

3.主库将新值同步到从库 

4.B操作将拿到的旧值写入缓存 

这就造成了缓存中的是旧值，数据库中的是新值，解决方法还是上面说的延迟双删，延迟时间要大于主从复制的时间

### 3.一个字符串类型的值能存储最大容量是多少？

512MB

### 4.Redis如何实现大量数据的插入？

**使用Luke协议**

使用正常模式的Redis 客户端执行大量数据插入不是一个好主意：因为一个个的插入会有大量的时间浪费在每一个命令往返时间上。**使用管道（pipelining ** [paɪplaɪnɪŋ]**）是一种可行的办法**，但是在大量插入数据的同时又需要执行其他新命令时，这时读取数据的同时需要确保请可能快的的写入数据。

只有一小部分的客户端支持非阻塞输入/输出(non-blocking I/O),并且并不是所有客户端能以最大限度的提高吞吐量的高效的方式来分析答复。

从Redis 2.6开始`redis-cli`支持一种新的被称之为**pipe mode**的新模式用于执行大量数据插入工作。

使用redis-cli将有效的确保错误输出到Redis实例的标准输出里面。

**使用Redis协议**

它会非常简单的生成和解析Redis协议，Redis协议文档请参考Redis协议说明。 但是为了生成大量数据插入的目标，你需要了解每一个细节协议

### 5.如何通过Redis实现异步队列？

主要有两种方式 

**RPUSH+ BLPOP**

第一种是使用List作为队列，通过RPUSH生产消息， LPOP消费消息 

存在的问题：如果队列是空的，客户端会不停的pop，陷入死循环 

解决方法： 

- 当lpop没有消息时，可以使用sleep机制先休眠一段时间，然后再检查有没有消息。 


- 可以使用BLPOP命令，在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。这种做法的缺点是只能提供一个消费者消费 

**PUB/SUB**

第二种方法是**pub/sub**主题订阅模式，发送者(pub)发送消息，订阅者(sub)接收消息 

存在的问题：消息的发布是无状态的，**无法保证到达**，如果订阅者在发送者发布消息时掉线，之后上线也无法接收发布者发送的消息 

解决方法：使用消息队列

### 6.如何通过Redis实现延时队列？

先说下延时队列的使用场景： 

- 常见的微信红包场景，A给B发红包，B没有收，1天后钱会退回原账户 
- 电商的订单支付场景，订单在半小时内未支付会自动取消 上述场景

可以通过定时任务采用数据库/非关系型数据库轮询方案或延迟队列，现主要介绍下Redis实现的延迟队列

可以通过Redis的**zset**命令实现延迟队列，ZSET是Redis的有序集合，通过zadd score1 value1命令向内存中生产消息，并利用设置好的**时间戳**作为score进行排序，然后通过zrangebysocre 查询符合条件的所有待处理的任务，循环执行，也可以zrangebyscore key min max withscores limit 0 1 查询最早的一条任务，来进行消费，如下图（画的第二种，好画点）

![img](https://image.mianshi.online/img202205252122851.jpg)

### 7.Redis回收使用什么算法？

Redis回收使用**LRU算法和引用计数法**

-  LRU算法很常见，在学习操作系统时也经常看到，淘汰最长时间没有被使用的对象，LRU算法在手撕代码环节也经常出现，要提前背熟 
-  引用计数法在学习JVM中也见过的，对于创建的每一个对象都有一个与之关联的计数器，这个计数器记录着该对象被使用的次数，当对象被一个新程序使用时，它的引用计数值会被增1，当对象不再被一个程序使用时，它的引用计数值会被减1，垃圾收集器在进行垃圾回收时，对扫描到的每一个对象判断一下计数器是否等于0，若等于0，就会释放该对象占用的内存空间，简单来说就是淘汰使用次数最少的对象（LFU算法）。

### 8.Redis 里面有1亿个 key，其中有 10 个 key 是包含 java，如何将它们全部找出来？

可以使用Redis的KEYS命令，用于查找所有匹配给定模式 pattern 的 key ，虽然时间复杂度为O(n)，但常量时间相当小。

**注意**: 生产环境使用 KEYS命令需要非常小心，在大的数据库上执行命令会影响性能，KEYS指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个命令适合用来调试和特殊操作，像改变键空间布局。 

不要在你的代码中使用 KEYS 。如果你需要一个寻找键空间中的key子集，考虑使用 **SCAN** 或 sets。
